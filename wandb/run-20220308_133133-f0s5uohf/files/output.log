WARNING:tensorflow:From main.py:32: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.config.list_physical_devices('GPU')` instead.
True
['ants', 'bees']
ConvNeXt(
  (downsample_layers): ModuleList(
    (0): Sequential(
      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (1): LayerNorm()
    )
    (1): Sequential(
      (0): LayerNorm()
      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
    )
    (2): Sequential(
      (0): LayerNorm()
      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
    )
    (3): Sequential(
      (0): LayerNorm()
      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (stages): ModuleList(
    (0): Sequential(
      (0): Block(
        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=96, out_features=384, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=384, out_features=96, bias=True)
        (drop_path): Identity()
      )
      (1): Block(
        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=96, out_features=384, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=384, out_features=96, bias=True)
        (drop_path): Identity()
      )
      (2): Block(
        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=96, out_features=384, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=384, out_features=96, bias=True)
        (drop_path): Identity()
      )
    )
    (1): Sequential(
      (0): Block(
        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=768, out_features=192, bias=True)
        (drop_path): Identity()
      )
      (1): Block(
        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=768, out_features=192, bias=True)
        (drop_path): Identity()
      )
      (2): Block(
        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=768, out_features=192, bias=True)
        (drop_path): Identity()
      )
    )
    (2): Sequential(
      (0): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (1): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (2): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (3): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (4): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (5): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (6): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (7): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (8): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
    )
    (3): Sequential(
      (0): Block(
        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
        (drop_path): Identity()
      )
      (1): Block(
        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
        (drop_path): Identity()
      )
      (2): Block(
        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
        (drop_path): Identity()
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=768, out_features=2, bias=True)
)
Epoch 0/35
----------
train: Loss: 1.0248 Acc: 0.4877
test: Loss: 0.7254 Acc: 0.5686
Epoch 1/35
----------
train: Loss: 0.7432 Acc: 0.5697
test: Loss: 0.9609 Acc: 0.5621
Epoch 2/35
----------
train: Loss: 0.8290 Acc: 0.5492
test: Loss: 0.8894 Acc: 0.5033
Epoch 3/35
----------
train: Loss: 0.7434 Acc: 0.5861
test: Loss: 1.0280 Acc: 0.5163
Epoch 4/35
----------
train: Loss: 0.8225 Acc: 0.5533
test: Loss: 0.7175 Acc: 0.6144
Epoch 5/35
----------
train: Loss: 0.7487 Acc: 0.5615
test: Loss: 0.7847 Acc: 0.5425
Epoch 6/35
----------
train: Loss: 0.7308 Acc: 0.5738
test: Loss: 0.6666 Acc: 0.6471
Epoch 7/35
----------
train: Loss: 0.6773 Acc: 0.5902
test: Loss: 0.6513 Acc: 0.6078
Epoch 8/35
----------
train: Loss: 0.6321 Acc: 0.6434
test: Loss: 0.6583 Acc: 0.5882
Epoch 9/35
----------
train: Loss: 0.6474 Acc: 0.5943
test: Loss: 0.6638 Acc: 0.5752
Epoch 10/35
----------
train: Loss: 0.6206 Acc: 0.6598
test: Loss: 0.6678 Acc: 0.5686
Epoch 11/35
----------
train: Loss: 0.6158 Acc: 0.6639
test: Loss: 0.6730 Acc: 0.5621
Epoch 12/35
----------
train: Loss: 0.6469 Acc: 0.6230
test: Loss: 0.6859 Acc: 0.6013
Epoch 13/35
----------
train: Loss: 0.6553 Acc: 0.6066
test: Loss: 0.6733 Acc: 0.6013
Epoch 14/35
----------
train: Loss: 0.6231 Acc: 0.6557
test: Loss: 0.6729 Acc: 0.6144
Epoch 15/35
----------
train: Loss: 0.6266 Acc: 0.6066
test: Loss: 0.6717 Acc: 0.6144
Epoch 16/35
----------
train: Loss: 0.6119 Acc: 0.6352
test: Loss: 0.6713 Acc: 0.6013
Epoch 17/35
----------
train: Loss: 0.6313 Acc: 0.6393
test: Loss: 0.6718 Acc: 0.6144
Epoch 18/35
----------
train: Loss: 0.6005 Acc: 0.6762
test: Loss: 0.6709 Acc: 0.6013
Epoch 19/35
----------
train: Loss: 0.6305 Acc: 0.6148
test: Loss: 0.6710 Acc: 0.5948
Epoch 20/35
----------
train: Loss: 0.6288 Acc: 0.6311
test: Loss: 0.6705 Acc: 0.5948
Epoch 21/35
----------
train: Loss: 0.6261 Acc: 0.6475
test: Loss: 0.6705 Acc: 0.5948
Epoch 22/35
----------
train: Loss: 0.6178 Acc: 0.6762
test: Loss: 0.6706 Acc: 0.5948
Epoch 23/35
----------
train: Loss: 0.6130 Acc: 0.6516
test: Loss: 0.6706 Acc: 0.5948
Epoch 24/35
----------
train: Loss: 0.6156 Acc: 0.6516
test: Loss: 0.6706 Acc: 0.5948
Epoch 25/35
----------
train: Loss: 0.6357 Acc: 0.6230
test: Loss: 0.6706 Acc: 0.5948
Epoch 26/35
----------
train: Loss: 0.6344 Acc: 0.6352
test: Loss: 0.6707 Acc: 0.6013
Epoch 27/35
----------
train: Loss: 0.6170 Acc: 0.6598
test: Loss: 0.6707 Acc: 0.6013
Epoch 28/35
----------
train: Loss: 0.6247 Acc: 0.6270
test: Loss: 0.6707 Acc: 0.6013
Epoch 29/35
----------
train: Loss: 0.6091 Acc: 0.6721
test: Loss: 0.6707 Acc: 0.6013
Epoch 30/35
----------
train: Loss: 0.6285 Acc: 0.6352
test: Loss: 0.6707 Acc: 0.6013
Epoch 31/35
----------
train: Loss: 0.6321 Acc: 0.6475
test: Loss: 0.6707 Acc: 0.6013
Epoch 32/35
----------
train: Loss: 0.6451 Acc: 0.6311
test: Loss: 0.6707 Acc: 0.6013
Epoch 33/35
----------
train: Loss: 0.6319 Acc: 0.6230
test: Loss: 0.6707 Acc: 0.6013
Epoch 34/35
----------
train: Loss: 0.6331 Acc: 0.6270
test: Loss: 0.6707 Acc: 0.6013
Epoch 35/35
----------
train: Loss: 0.6398 Acc: 0.6475
test: Loss: 0.6707 Acc: 0.6013
Training complete in 2m 33s
Best val Acc: 0.647059