True
['ants', 'bees']
WARNING:tensorflow:From main.py:32: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.config.list_physical_devices('GPU')` instead.
ConvNeXt(
  (downsample_layers): ModuleList(
    (0): Sequential(
      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (1): LayerNorm()
    )
    (1): Sequential(
      (0): LayerNorm()
      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
    )
    (2): Sequential(
      (0): LayerNorm()
      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
    )
    (3): Sequential(
      (0): LayerNorm()
      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (stages): ModuleList(
    (0): Sequential(
      (0): Block(
        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=96, out_features=384, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=384, out_features=96, bias=True)
        (drop_path): Identity()
      )
      (1): Block(
        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=96, out_features=384, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=384, out_features=96, bias=True)
        (drop_path): Identity()
      )
      (2): Block(
        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=96, out_features=384, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=384, out_features=96, bias=True)
        (drop_path): Identity()
      )
    )
    (1): Sequential(
      (0): Block(
        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=768, out_features=192, bias=True)
        (drop_path): Identity()
      )
      (1): Block(
        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=768, out_features=192, bias=True)
        (drop_path): Identity()
      )
      (2): Block(
        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=768, out_features=192, bias=True)
        (drop_path): Identity()
      )
    )
    (2): Sequential(
      (0): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (1): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (2): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (3): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (4): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (5): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (6): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (7): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (8): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
    )
    (3): Sequential(
      (0): Block(
        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
        (drop_path): Identity()
      )
      (1): Block(
        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
        (drop_path): Identity()
      )
      (2): Block(
        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
        (drop_path): Identity()
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=768, out_features=2, bias=True)
)
Epoch 0/39
----------
train: Loss: 0.7520 Acc: 0.6230
test: Loss: 0.8755 Acc: 0.5033
Epoch 1/39
----------
train: Loss: 0.8417 Acc: 0.5082
test: Loss: 0.7698 Acc: 0.6078
Epoch 2/39
----------
train: Loss: 0.7489 Acc: 0.6107
test: Loss: 0.8354 Acc: 0.5163
Epoch 3/39
----------
train: Loss: 0.7886 Acc: 0.5328
test: Loss: 0.7810 Acc: 0.4706
Epoch 4/39
----------
train: Loss: 0.7325 Acc: 0.5779
test: Loss: 0.7465 Acc: 0.5686
Epoch 5/39
----------
train: Loss: 0.7612 Acc: 0.5738
test: Loss: 0.7488 Acc: 0.5425
Epoch 6/39
----------
train: Loss: 0.7249 Acc: 0.5738
test: Loss: 0.7967 Acc: 0.4771
Epoch 7/39
----------
train: Loss: 0.7015 Acc: 0.5656
test: Loss: 0.7123 Acc: 0.5033
Epoch 8/39
----------
train: Loss: 0.6518 Acc: 0.5984
test: Loss: 0.7116 Acc: 0.5621
Epoch 9/39
----------
train: Loss: 0.6460 Acc: 0.5984
test: Loss: 0.7109 Acc: 0.5359
Epoch 10/39
----------
train: Loss: 0.6350 Acc: 0.6148
test: Loss: 0.7180 Acc: 0.5556
Epoch 11/39
----------
train: Loss: 0.6435 Acc: 0.6352
test: Loss: 0.7096 Acc: 0.5686
Epoch 12/39
----------
train: Loss: 0.6390 Acc: 0.6352
test: Loss: 0.7150 Acc: 0.5752
Epoch 13/39
----------
train: Loss: 0.6248 Acc: 0.6557
test: Loss: 0.7128 Acc: 0.5752
Epoch 14/39
----------
train: Loss: 0.6231 Acc: 0.6230
test: Loss: 0.7124 Acc: 0.5817
Epoch 15/39
----------
train: Loss: 0.6349 Acc: 0.6393
test: Loss: 0.7123 Acc: 0.5817
Epoch 16/39
----------
train: Loss: 0.6208 Acc: 0.6107
test: Loss: 0.7111 Acc: 0.5817
Epoch 17/39
----------
train: Loss: 0.6223 Acc: 0.6557
test: Loss: 0.7112 Acc: 0.5817
Epoch 18/39
----------
train: Loss: 0.6158 Acc: 0.6311
test: Loss: 0.7100 Acc: 0.5817
Epoch 19/39
----------
train: Loss: 0.6157 Acc: 0.6557
test: Loss: 0.7095 Acc: 0.5882
Epoch 20/39
----------
train: Loss: 0.6458 Acc: 0.6475
test: Loss: 0.7092 Acc: 0.5882
Epoch 21/39
----------
train: Loss: 0.6260 Acc: 0.6639
test: Loss: 0.7092 Acc: 0.5882
Epoch 22/39
----------
train: Loss: 0.6522 Acc: 0.5738
test: Loss: 0.7092 Acc: 0.5882
Epoch 23/39
----------
train: Loss: 0.6299 Acc: 0.6311
test: Loss: 0.7092 Acc: 0.5882
Epoch 24/39
----------
train: Loss: 0.6157 Acc: 0.6434
test: Loss: 0.7091 Acc: 0.5882
Epoch 25/39
----------
train: Loss: 0.6556 Acc: 0.5902
test: Loss: 0.7090 Acc: 0.5882
Epoch 26/39
----------
train: Loss: 0.6378 Acc: 0.6352
test: Loss: 0.7090 Acc: 0.5882
Epoch 27/39
----------
train: Loss: 0.6409 Acc: 0.6270
test: Loss: 0.7089 Acc: 0.5882
Epoch 28/39
----------
train: Loss: 0.6350 Acc: 0.6270
test: Loss: 0.7089 Acc: 0.5882
Epoch 29/39
----------
train: Loss: 0.6352 Acc: 0.6352
test: Loss: 0.7089 Acc: 0.5882
Epoch 30/39
----------
train: Loss: 0.6455 Acc: 0.6148
test: Loss: 0.7089 Acc: 0.5882
Epoch 31/39
----------
train: Loss: 0.6213 Acc: 0.6189
test: Loss: 0.7089 Acc: 0.5882
Epoch 32/39
----------
train: Loss: 0.6344 Acc: 0.6148
test: Loss: 0.7089 Acc: 0.5882
Epoch 33/39
----------
train: Loss: 0.6495 Acc: 0.6066
test: Loss: 0.7089 Acc: 0.5882
Epoch 34/39
----------
train: Loss: 0.6289 Acc: 0.6107
test: Loss: 0.7089 Acc: 0.5882
Epoch 35/39
----------
train: Loss: 0.6292 Acc: 0.6434
test: Loss: 0.7089 Acc: 0.5882
Epoch 36/39
----------
train: Loss: 0.6387 Acc: 0.6598
test: Loss: 0.7089 Acc: 0.5882
Epoch 37/39
----------
train: Loss: 0.6632 Acc: 0.5902
test: Loss: 0.7089 Acc: 0.5882
Epoch 38/39
----------
train: Loss: 0.6383 Acc: 0.6107
test: Loss: 0.7089 Acc: 0.5882
Epoch 39/39
----------
train: Loss: 0.6393 Acc: 0.6189
test: Loss: 0.7089 Acc: 0.5882
Training complete in 2m 28s
Best val Acc: 0.607843