WARNING:tensorflow:From main.py:32: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.config.list_physical_devices('GPU')` instead.
True
['ants', 'bees']
ConvNeXt(
  (downsample_layers): ModuleList(
    (0): Sequential(
      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))
      (1): LayerNorm()
    )
    (1): Sequential(
      (0): LayerNorm()
      (1): Conv2d(96, 192, kernel_size=(2, 2), stride=(2, 2))
    )
    (2): Sequential(
      (0): LayerNorm()
      (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))
    )
    (3): Sequential(
      (0): LayerNorm()
      (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))
    )
  )
  (stages): ModuleList(
    (0): Sequential(
      (0): Block(
        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=96, out_features=384, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=384, out_features=96, bias=True)
        (drop_path): Identity()
      )
      (1): Block(
        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=96, out_features=384, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=384, out_features=96, bias=True)
        (drop_path): Identity()
      )
      (2): Block(
        (dwconv): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=96, out_features=384, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=384, out_features=96, bias=True)
        (drop_path): Identity()
      )
    )
    (1): Sequential(
      (0): Block(
        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=768, out_features=192, bias=True)
        (drop_path): Identity()
      )
      (1): Block(
        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=768, out_features=192, bias=True)
        (drop_path): Identity()
      )
      (2): Block(
        (dwconv): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=192, out_features=768, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=768, out_features=192, bias=True)
        (drop_path): Identity()
      )
    )
    (2): Sequential(
      (0): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (1): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (2): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (3): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (4): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (5): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (6): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (7): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
      (8): Block(
        (dwconv): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=384, out_features=1536, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=1536, out_features=384, bias=True)
        (drop_path): Identity()
      )
    )
    (3): Sequential(
      (0): Block(
        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
        (drop_path): Identity()
      )
      (1): Block(
        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
        (drop_path): Identity()
      )
      (2): Block(
        (dwconv): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)
        (norm): LayerNorm()
        (pwconv1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU()
        (pwconv2): Linear(in_features=3072, out_features=768, bias=True)
        (drop_path): Identity()
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=768, out_features=2, bias=True)
)
Epoch 0/41
----------
train: Loss: 1.0366 Acc: 0.5041
test: Loss: 1.0272 Acc: 0.5229
Epoch 1/41
----------
train: Loss: 0.9608 Acc: 0.4795
test: Loss: 0.8489 Acc: 0.5425
Epoch 2/41
----------
train: Loss: 0.9163 Acc: 0.5615
test: Loss: 0.7879 Acc: 0.5490
Epoch 3/41
----------
train: Loss: 0.8412 Acc: 0.5369
test: Loss: 0.8273 Acc: 0.5425
Epoch 4/41
----------
train: Loss: 0.7962 Acc: 0.5615
test: Loss: 0.7850 Acc: 0.4967
Epoch 5/41
----------
train: Loss: 0.7358 Acc: 0.5615
test: Loss: 0.7879 Acc: 0.5359
Epoch 6/41
----------
train: Loss: 0.7279 Acc: 0.6025
test: Loss: 1.0050 Acc: 0.5556
Epoch 7/41
----------
train: Loss: 0.7537 Acc: 0.6107
test: Loss: 0.6897 Acc: 0.5882
Epoch 8/41
----------
train: Loss: 0.6728 Acc: 0.5861
test: Loss: 0.6921 Acc: 0.6013
Epoch 9/41
----------
train: Loss: 0.6505 Acc: 0.5943
test: Loss: 0.6908 Acc: 0.5752
Epoch 10/41
----------
train: Loss: 0.6515 Acc: 0.6148
test: Loss: 0.7103 Acc: 0.5752
Epoch 11/41
----------
train: Loss: 0.6602 Acc: 0.5984
test: Loss: 0.7036 Acc: 0.5556
Epoch 12/41
----------
train: Loss: 0.6361 Acc: 0.6393
test: Loss: 0.7130 Acc: 0.5556
Epoch 13/41
----------
train: Loss: 0.6614 Acc: 0.5820
test: Loss: 0.7029 Acc: 0.5752
Epoch 14/41
----------
train: Loss: 0.6206 Acc: 0.6434
test: Loss: 0.7039 Acc: 0.5752
Epoch 15/41
----------
train: Loss: 0.6269 Acc: 0.6434
test: Loss: 0.7032 Acc: 0.5686
Epoch 16/41
----------
train: Loss: 0.6387 Acc: 0.6189
test: Loss: 0.7027 Acc: 0.5686
Epoch 17/41
----------
train: Loss: 0.6455 Acc: 0.6393
test: Loss: 0.7025 Acc: 0.5752
Epoch 18/41
----------
train: Loss: 0.5965 Acc: 0.6885
test: Loss: 0.7021 Acc: 0.5817
Epoch 19/41
----------
train: Loss: 0.6339 Acc: 0.6352
test: Loss: 0.7007 Acc: 0.5686
Epoch 20/41
----------
train: Loss: 0.6276 Acc: 0.6762
test: Loss: 0.6996 Acc: 0.5817
Epoch 21/41
----------
train: Loss: 0.6410 Acc: 0.6230
test: Loss: 0.6995 Acc: 0.5817
Epoch 22/41
----------
train: Loss: 0.6322 Acc: 0.6189
test: Loss: 0.6995 Acc: 0.5817
Epoch 23/41
----------
train: Loss: 0.6205 Acc: 0.6557
test: Loss: 0.6994 Acc: 0.5817
Epoch 24/41
----------
train: Loss: 0.6449 Acc: 0.6475
test: Loss: 0.6994 Acc: 0.5817
Epoch 25/41
----------
train: Loss: 0.6139 Acc: 0.6557
test: Loss: 0.6993 Acc: 0.5817
Epoch 26/41
----------
train: Loss: 0.6448 Acc: 0.6148
test: Loss: 0.6993 Acc: 0.5817
Epoch 27/41
----------
train: Loss: 0.6235 Acc: 0.6270
test: Loss: 0.6993 Acc: 0.5817
Epoch 28/41
----------
train: Loss: 0.6414 Acc: 0.6025
test: Loss: 0.6993 Acc: 0.5817
Epoch 29/41
----------
train: Loss: 0.6323 Acc: 0.6516
test: Loss: 0.6993 Acc: 0.5817
Epoch 30/41
----------
train: Loss: 0.6403 Acc: 0.6434
test: Loss: 0.6993 Acc: 0.5817
Epoch 31/41
----------
train: Loss: 0.6188 Acc: 0.6639
test: Loss: 0.6993 Acc: 0.5817
Epoch 32/41
----------
train: Loss: 0.6114 Acc: 0.6598
test: Loss: 0.6993 Acc: 0.5817
Epoch 33/41
----------
train: Loss: 0.6242 Acc: 0.6230
test: Loss: 0.6993 Acc: 0.5817
Epoch 34/41
----------
train: Loss: 0.6423 Acc: 0.6352
test: Loss: 0.6993 Acc: 0.5817
Epoch 35/41
----------
train: Loss: 0.6494 Acc: 0.6270
test: Loss: 0.6993 Acc: 0.5817
Epoch 36/41
----------
train: Loss: 0.6361 Acc: 0.6066
test: Loss: 0.6993 Acc: 0.5817
Epoch 37/41
----------
train: Loss: 0.6555 Acc: 0.5902
test: Loss: 0.6993 Acc: 0.5817
Epoch 38/41
----------
train: Loss: 0.6545 Acc: 0.6148
test: Loss: 0.6993 Acc: 0.5817
Epoch 39/41
----------
train: Loss: 0.6069 Acc: 0.6475
test: Loss: 0.6993 Acc: 0.5817
Epoch 40/41
----------
train: Loss: 0.6442 Acc: 0.5697
test: Loss: 0.6993 Acc: 0.5817
Epoch 41/41
----------
train: Loss: 0.6247 Acc: 0.6230
test: Loss: 0.6993 Acc: 0.5817
Training complete in 3m 14s
Best val Acc: 0.601307